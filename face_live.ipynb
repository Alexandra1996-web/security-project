{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1 # MTCNN para identificar la cara formato ya lo trae entrenado en el modelo\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "#Proyecto que reconozca e identifique que va a ser la cara de alex etc. \n",
    "\n",
    "# Inicializar MTCNN y InceptionResnetV1\n",
    "\n",
    "mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40)\n",
    "mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=40) #reconocer de quien es la cara . En la carpeta poner le nombre de la persona. Al encender la camara decir que es el y por otra parte en que parte esta la caradentro dela \n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()  #Modelo Preentrenado\n",
    "\n",
    "# Cargar las imagenes\n",
    "\n",
    "dataset = datasets.ImageFolder('C:\\\\Users\\\\FUNDACION NATAN\\\\Desktop\\\\PENGUIN ACADEMY\\\\Penguin\\\\live_face_recognition-main\\\\photos') # Cargar las fotos contiene las iamgenes de las personas\n",
    "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
    "\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "name_list = [] # nombres correspondientes a las fotos\n",
    "embedding_list = [] # lista conteniendo las representaciones matriciales usando la resnet es la esencia matematica de la cara de alex \n",
    "for img, idx in loader:\n",
    "    face, prob = mtcnn0(img, return_prob=True) # probabilidad reconocer la cara de alex \n",
    "    if face is not None and prob>0.92:\n",
    "        emb = resnet(face.unsqueeze(0))\n",
    "        embedding_list.append(emb.detach())\n",
    "        name_list.append(idx_to_class[idx])\n",
    "#name list fabri y marc\n",
    "# Guardamos los datos generados para luego poder identificar las caras\n",
    "data = [embedding_list, name_list]\n",
    "torch.save(data, 'C:\\\\Users\\\\FUNDACION NATAN\\\\Desktop\\\\PENGUIN ACADEMY\\\\Penguin\\\\live_face_recognition-main\\\\photos\\\\data.pt')\n",
    "\n",
    "# Cargar el modelo\n",
    "load_data = torch.load('C:\\\\Users\\\\FUNDACION NATAN\\\\Desktop\\\\PENGUIN ACADEMY\\\\Penguin\\\\live_face_recognition-main\\\\photos\\\\data.pt')\n",
    "embedding_list = load_data[0]\n",
    "name_list = load_data[1]\n",
    "\n",
    "#frame es fotograma pro segundo \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"fail to grab frame, try again\")\n",
    "        break\n",
    "\n",
    "    img = Image.fromarray(frame)\n",
    "\n",
    "    # Utilizamos mtcnn para idenficar la CARA de la persona\n",
    "    img_cropped_list, prob_list = mtcnn(img, return_prob=True)\n",
    "\n",
    "    if img_cropped_list is not None:\n",
    "\n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "        for i, prob in enumerate(prob_list):\n",
    "            # si la probabilidad de que sea una cara es >90\n",
    "            if prob>0.90:\n",
    "                # Realizamos el embeding de la imagen capturada\n",
    "                emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()\n",
    "\n",
    "                dist_list = []\n",
    "                # Calculamos las distancias de todos los puntos del modelo con la imagen que estamos capturando\n",
    "                # La pareja que menos distancia tenga es la persona reconocida\n",
    "\n",
    "                for idx, emb_db in enumerate(embedding_list): # Comparamos 1 a 1 con nuestra base de datos\n",
    "                    dist = torch.dist(emb, emb_db).item()\n",
    "                    dist_list.append(dist)\n",
    "\n",
    "                min_dist = min(dist_list) # Cogemos el minimo valor (el que mas se parece)\n",
    "                min_dist_idx = dist_list.index(min_dist) # Indice del menor valor\n",
    "                name = name_list[min_dist_idx] # Nombre de la persona correspondiente al minimo valor\n",
    "\n",
    "                box = boxes[i] # recuadro de la cara correspondiente\n",
    "\n",
    "                # Guardamos una copia del frame procesado y a√±adimos recuadro reconocimiento facial\n",
    "                # + distancia y Nombre de la persona\n",
    "\n",
    "                original_frame = frame.copy()\n",
    "\n",
    "                if min_dist<0.90:\n",
    "                    frame = cv2.putText(frame, name+' '+str(min_dist), (box[0],box[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),1, cv2.LINE_AA)\n",
    "\n",
    "                frame = cv2.rectangle(frame, (box[0],box[1]) , (box[2],box[3]), (255,0,0), 2)\n",
    "\n",
    "    # Mostramos la imagen con dibujo y Nombre\n",
    "    cv2.imshow(\"IMG\", frame)\n",
    "\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256==27:\n",
    "        print('Esc pressed, closing...')\n",
    "        #break\n",
    "\n",
    "    elif k%256==32:\n",
    "        print('Enter your name :')\n",
    "        name = input()\n",
    "\n",
    "        if not os.path.exists('/Users/MarcSanmillan/Desktop/Penguin /live_face_recognition-main/photos/'+name):\n",
    "            os.mkdir('photos/'+name)\n",
    "\n",
    "        img_name = \"/Users/MarcSanmillan/Desktop/Penguin /live_face_recognition-main/photoss/{}/{}.jpg\".format(name, int(time.time()))\n",
    "        cv2.imwrite(img_name, original_frame)\n",
    "        print(\" saved: {}\".format(img_name))\n",
    "\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
